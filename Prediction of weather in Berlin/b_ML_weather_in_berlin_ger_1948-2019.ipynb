{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of the temperature in Berlin, GER.\n",
    "\n",
    "It was one of my first projects in Machine Learning. The dataset include the meteorological information from Berlin from the period between 1948 until 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using qt5 instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "pd.options.display.width = 0\n",
    "pd.options.display.max_rows = None\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preparing data.\n",
    "\n",
    "Let's read the data first and choose the most interesting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('berlin_klima_1948_2019_en.txt', sep=';')\n",
    "less_columns = [\"Station_ID\", \"QN_3\", \"QN_4\", \"VPM\", \"eor\", \"Average_air_pressure\", \"Medium_Wind_Speed\",\n",
    "                \"Precipitation_form\", \"Means_of_coverage\", \"Daily_mean_temp\", \"Daily_min_temp_ground\"]\n",
    "data.drop(less_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets replace some infinit numbers with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(-999.0, np.nan)\n",
    "data = data.replace(-999, np.nan)\n",
    "data.reset_index(inplace=True)\n",
    "data = data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('use_inf_as_na', True)\n",
    "data = data.replace([np.inf, -np.inf], 0).dropna(subset=data.columns, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and scalling data.\n",
    "\n",
    "Beacause it is a continous data we I will split it by hand. To scale the data I will use MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = \"Daily_max_temp\"\n",
    "\n",
    "X = np.array(data.drop([predict], axis=1))\n",
    "y = np.array(data[predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SPLITTING FOR TIME SERIES'''\n",
    "X_train = X[:int(X.shape[0]*0.7)]\n",
    "X_test = X[int(X.shape[0]*0.7):]\n",
    "y_train = y[:int(X.shape[0]*0.7)]\n",
    "y_test = y[int(X.shape[0]*0.7):]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of continous detaset I will use for cross validation TimeSeriesSplit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LINEAR REGRESSION'''\n",
    "def lin_reg():\n",
    "    linear = linear_model.LinearRegression()\n",
    "    linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"\\nCross validation for Linear Regression:\")\n",
    "    lin_reg_scores = cross_val_score(linear, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    lin_reg_rmse_scores = np.sqrt(-lin_reg_scores)\n",
    "    display_scores(lin_reg_rmse_scores)\n",
    "\n",
    "    predictions = linear.predict(X_test_scaled) # Gets a list of all predictions\n",
    "    predictions_train = linear.predict(X_train_scaled)\n",
    "\n",
    "    score_r2_lin = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Linear Regression test:\\n\", score_r2_lin)\n",
    "\n",
    "    lin_mse = mean_squared_error(y_test, predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    print(\"\\nMSE of Linear Regression test:\\n\", lin_mse)\n",
    "    print(\"\\nRMSE of Linear Regression test:\\n\", lin_rmse)\n",
    "\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POLYNOMIAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''POLYNOMIAL FEATURES'''\n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "scaler.fit(X_train_poly)\n",
    "# scaler.fit(X_test_poly)\n",
    "X_train_poly_scaled = scaler.transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''POLYNOMIAL FEATURES WITH LINEAR REGRESSION (POLYNOMIAL REGRESSION)'''\n",
    "def poly_reg():\n",
    "    linear = linear_model.LinearRegression()\n",
    "    linear.fit(X_train_poly, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Polynomial Regression:\")\n",
    "    poly_reg_scores = cross_val_score(linear, X_train_poly, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    poly_reg_rmse_scores = np.sqrt(-poly_reg_scores)\n",
    "    display_scores(poly_reg_rmse_scores)\n",
    "\n",
    "    predictions = linear.predict(X_test_poly)\n",
    "    predictions_train = linear.predict(X_train_poly)\n",
    "\n",
    "    score_r2_poly = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Polynomial Regression test:\\n\", score_r2_poly)\n",
    "\n",
    "    lin_mse_poly = mean_squared_error(y_test, predictions)\n",
    "    lin_rmse_poly = np.sqrt(lin_mse_poly)\n",
    "    print(\"\\nMSE of Polynomial Regression test:\\n\", lin_mse_poly)\n",
    "    print(\"\\nRMSE of Polynomial Regression test:\\n\", lin_rmse_poly)\n",
    "\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RIDGE REGRESSION'''\n",
    "def ridge_reg():\n",
    "    linear_ridge = linear_model.Ridge()\n",
    "    linear_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Ridge Regression:\")\n",
    "    ridge_reg_scores = cross_val_score(linear_ridge, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    ridge_reg_rmse_scores = np.sqrt(-ridge_reg_scores)\n",
    "    display_scores(ridge_reg_rmse_scores)\n",
    "\n",
    "    predictions = linear_ridge.predict(X_test_scaled)\n",
    "    predictions_train = linear_ridge.predict(X_train_scaled)\n",
    "\n",
    "    score_r2_ridge = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Ridge Regression test:\\n\", score_r2_ridge)\n",
    "\n",
    "    lin_mse_ridge = mean_squared_error(y_test, predictions)\n",
    "    lin_rmse_ridge = np.sqrt(lin_mse_ridge)\n",
    "    print(\"\\nMSE of Ridge Regression test:\\n\", lin_mse_ridge)\n",
    "    print(\"\\nRMSE of Ridge Regression test:\\n\", lin_rmse_ridge)\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RIDGE REGRESSION WITH POLYNOMIAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RIDGE REGRESSION WITH POLYNOMIAL FEATURES'''\n",
    "def ridge_reg_poly():\n",
    "    linear_ridge_poly = linear_model.Ridge()\n",
    "    linear_ridge_poly.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Polynomial Ridge Regression:\")\n",
    "    poly_ridge_reg_scores = cross_val_score(linear_ridge_poly, X_train_poly_scaled, y_train,\n",
    "                                            scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    poly_ridge_reg_rmse_scores = np.sqrt(-poly_ridge_reg_scores)\n",
    "    display_scores(poly_ridge_reg_rmse_scores)\n",
    "\n",
    "    predictions = linear_ridge_poly.predict(X_test_poly_scaled)\n",
    "    predictions_train = linear_ridge_poly.predict(X_train_poly_scaled)\n",
    "\n",
    "    score_r2_ridge_poly = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Polynomial Ridge Regression test:\\n\", score_r2_ridge_poly)\n",
    "\n",
    "    lin_mse_ridge_poly = mean_squared_error(y_test, predictions)\n",
    "    lin_rmse_ridge_poly = np.sqrt(lin_mse_ridge_poly)\n",
    "    print(\"\\nMSE of Polynomial Ridge Regression test:\\n\", lin_mse_ridge_poly)\n",
    "    print(\"\\nRMSE of Polynomial Ridge Regression test:\\n\", lin_rmse_ridge_poly)\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RANDOM FOREST'''\n",
    "def rand_forests():\n",
    "    forest = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Random Forest:\")\n",
    "    forest_scores = cross_val_score(forest, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "    display_scores(forest_rmse_scores)\n",
    "\n",
    "    predictions = forest.predict(X_test)\n",
    "    predictions_train = forest.predict(X_train)\n",
    "\n",
    "    score_r2_forest = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Random Forest test:\\n\", score_r2_forest)\n",
    "\n",
    "    mse_random_forest = mean_squared_error(y_test, predictions)\n",
    "    rmse_random_forest = np.sqrt(mse_random_forest)\n",
    "    print(\"\\nMSE of Random Forest test:\\n\", mse_random_forest)\n",
    "    print(\"\\nRMSE of Random Forest test:\\n\", rmse_random_forest)\n",
    "\n",
    "    feature_names = list(data)\n",
    "    print(sorted(zip(map(lambda x: round(x, 4), forest.feature_importances_), feature_names),\n",
    "                reverse=True))\n",
    "\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GRADIENT BOOST REGRESSOR FOR RANDOM FOREST WITH EARLY STOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRADIENT BOOST REGRESSOR FOR RANDOM FOREST WITH EARLY STOPPING'''\n",
    "def gbrt_1():\n",
    "    gbrt = GradientBoostingRegressor(learning_rate=0.1)\n",
    "    gbrt.fit(X_train, y_train)\n",
    "\n",
    "    errors = [mean_squared_error(y_test, y_pred)\n",
    "                for y_pred in gbrt.staged_predict(X_test)]\n",
    "    bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "    gbrt_best = GradientBoostingRegressor(n_estimators=bst_n_estimators)\n",
    "    gbrt_best.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Gradient Boost Regressor:\")\n",
    "    gbrt_scores = cross_val_score(gbrt_best, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    gbrt_rmse_scores = np.sqrt(-gbrt_scores)\n",
    "    display_scores(gbrt_rmse_scores)\n",
    "\n",
    "    predictions = gbrt_best.predict(X_test)\n",
    "    predictions_train = gbrt.predict(X_train)\n",
    "\n",
    "    score_r2_gbrt_1 = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Random Gradient Boost Regressor test:\\n\", score_r2_gbrt_1)\n",
    "\n",
    "    mse_gbrt = mean_squared_error(y_test, predictions)\n",
    "    rmse_gbrt = np.sqrt(mse_gbrt)\n",
    "    print(\"\\nMSE of Gradient Boosting Reg with Early Stopping test:\\n\", mse_gbrt)\n",
    "    print(\"\\nRMSE of Gradient Boosting Reg with Early Stopping test:\\n\", rmse_gbrt)\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EXTREME GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EXTREME GRADIENT BOOSTING'''\n",
    "def xgb():\n",
    "    xgb_reg = xgboost.XGBRegressor()\n",
    "    xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n\\tCross validation for Extreme Gradient Boosting:\")\n",
    "    xgb_scores = cross_val_score(xgb_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=tscv)\n",
    "    xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "    display_scores(xgb_rmse_scores)\n",
    "\n",
    "    predictions = xgb_reg.predict(X_test)\n",
    "    predictions_train = xgb_reg.predict(X_train)\n",
    "    \n",
    "    score_r2_xgb = r2_score(y_test, predictions)\n",
    "    print(\"\\nR2 of Extreme Gradient Boosting test:\\n\", score_r2_xgb)\n",
    "\n",
    "    mse_xgb = mean_squared_error(y_test, predictions)\n",
    "    rmse_xgb = np.sqrt(mse_xgb)\n",
    "    print(\"\\nMSE of Extreme Gradient Boosting Reg test:\\n\", mse_xgb)\n",
    "    print(\"\\nRMSE of Extreme Gradient Boosting Reg test:\\n\", rmse_xgb, \"\\n\")\n",
    "\n",
    "    xgb_reg.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10)\n",
    "    predictions = xgb_reg.predict(X_test)\n",
    "    return predictions, predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EVALUATION WITH CROSS-VALIDATION'''\n",
    "def display_scores(scores):\n",
    "    print(\"\\nScores:\\n\", scores)\n",
    "    print(\"Mean:\\n\", scores.mean())\n",
    "    print(\"Standard deviation:\\n\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LET'S SEE HOW EACH MODEL IS WORKING:\n",
    "\n",
    "To check each model just change the name of function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCross validation for Gradient Boost Regressor:\n",
      "\n",
      "Scores:\n",
      " [2.45700649 2.61718392 2.71882256 2.42349731 2.41835414 2.18812568\n",
      " 2.02940613 2.05587179 2.02560652 2.16771774]\n",
      "Mean:\n",
      " 2.310159227697148\n",
      "Standard deviation:\n",
      " 0.23812225221399563\n",
      "\n",
      "R2 of Random Gradient Boost Regressor test:\n",
      " 0.9443318162903325\n",
      "\n",
      "MSE of Gradient Boosting Reg with Early Stopping test:\n",
      " 4.6147634804432265\n",
      "\n",
      "RMSE of Gradient Boosting Reg with Early Stopping test:\n",
      " 2.148200055963882\n"
     ]
    }
   ],
   "source": [
    "'''Lets try to plot some predictions'''\n",
    "predictions, predictions_train = gbrt_1() #here change the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LETS PLOT THE PREDICTIONS:\n",
    "\n",
    "The plot will pop up in separate window for better interaction like zooming etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = (len(data['Measurement_date'])) * 0.7\n",
    "n_train = int(n_train)\n",
    "# print(n_train)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.xticks(rotation=90, ha=\"left\")\n",
    "plt.plot(range(n_train), y_train, label=\"train\")\n",
    "plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label=\"test\")\n",
    "plt.plot(range(n_train), predictions_train, '--', label=\"prediction train\")\n",
    "plt.plot(range(n_train, len(y_test) + n_train), predictions, '--', label=\"prediction test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Max temp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS\n",
    "\n",
    "## Here we can see that almost all machine learning algorithms got more or less similar results. The best results delivered Boosting algorithms: \n",
    "\n",
    "## Gradient Boosting (R2=0.944, RMSE=2.148) and \n",
    "\n",
    "## XGB(R2=0942, RMSE=2.176)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LINEAR REGRESSION RESULTS:\n",
    "\n",
    "Cross validation for Linear Regression:\n",
    "\n",
    "Scores:\n",
    " [2.69014802 2.85776279 2.41132115 2.37598251 2.42985339 2.29297009\n",
    " 2.15743709 2.20029233 2.13725814 2.26922508]\n",
    "\n",
    "Mean:\n",
    " 2.3822250588544547\n",
    "\n",
    "Standard deviation:\n",
    " 0.22101585344493974\n",
    "\n",
    "------------------------------------------------\n",
    "R2 of Linear Regression test:\n",
    " 0.9263779505581495\n",
    "\n",
    "MSE of Linear Regression test:\n",
    " 6.103097361529968\n",
    "\n",
    "RMSE of Linear Regression test:\n",
    " 2.470444769981707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POLYNOMIAL REGRESSION RESULTS:\n",
    "\n",
    "Cross validation for Polynomial Regression:\n",
    "\n",
    "Scores:\n",
    " [ 4.80482718  2.48830131  3.04636984  2.62600513 46.14622877  5.94219531\n",
    "  3.2856642   2.10450459  2.06727117  2.12711101]\n",
    "\n",
    "Mean:\n",
    " 7.463847850614847\n",
    "\n",
    "Standard deviation:\n",
    " 12.950563259134865\n",
    "\n",
    "-----------------------------------------\n",
    "R2 of Polynomial Regression test:\n",
    " 0.9322318138152672\n",
    "\n",
    "MSE of Polynomial Regression test:\n",
    " 5.617825657330935\n",
    "\n",
    "RMSE of Polynomial Regression test:\n",
    " 2.37019527831167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RIDGE REGRESSION RESULTS:\n",
    "\n",
    "Cross validation for Ridge Regression:\n",
    "\n",
    "Scores:\n",
    " [2.40474235 2.82957922 2.4142921  2.37340007 2.43529665 2.29073264\n",
    " 2.15844    2.19957283 2.13587742 2.27041034]\n",
    "\n",
    "Mean:\n",
    " 2.351234362847367\n",
    "\n",
    "Standard deviation:\n",
    " 0.1897243921099501\n",
    "\n",
    "------------------------------------------------\n",
    "R2 of Ridge Regression test:\n",
    " 0.9262452047257254\n",
    "\n",
    "MSE of Ridge Regression test:\n",
    " 6.114101683547128\n",
    "\n",
    "RMSE of Ridge Regression test:\n",
    " 2.4726709614396993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RIDGE REGRESSION WITH POLYNOMIAL FEATURES; RESULTS:\n",
    "\n",
    "Cross validation for Polynomial Ridge Regression:\n",
    "\n",
    "Scores:\n",
    " [2.4920935  2.85777905 2.3653337  2.32336092 2.39265696 2.14215718\n",
    " 2.03544494 2.04889615 2.0033719  2.09349863]\n",
    "\n",
    "Mean:\n",
    " 2.275459293883859\n",
    "\n",
    "Standard deviation:\n",
    " 0.2537680772651603\n",
    "\n",
    "-----------------------------------------\n",
    "R2 of Polynomial Ridge Regression test:\n",
    " 0.9384322757889232\n",
    "\n",
    "MSE of Polynomial Ridge Regression test:\n",
    " 5.103821722387828\n",
    "\n",
    "RMSE of Polynomial Ridge Regression test:\n",
    " 2.2591639432294035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RANDOM FOREST RESULTS:\n",
    "\n",
    "Cross validation for Random Forest:\n",
    "\n",
    "Scores:\n",
    " [2.68005958 2.85854262 2.84061447 2.6206457  2.74873958 2.45223132\n",
    " 2.32159746 2.25270899 2.22711817 2.24519145]\n",
    "\n",
    "Mean:\n",
    " 2.5247449323292614\n",
    "\n",
    "Standard deviation:\n",
    " 0.24123643401056097\n",
    "\n",
    "-----------------------------------------\n",
    "R2 of Random Forest test:\n",
    " 0.9349815114683627\n",
    "\n",
    "MSE of Random Forest test:\n",
    " 5.389882091254753\n",
    "\n",
    "RMSE of Random Forest test:\n",
    " 2.3216119596639646\n",
    "\n",
    "Features importance:\n",
    "[(0.8692, 'Daily_max_temp'), (0.0788, 'Daily_mean_humidity'), (0.0205, 'Measurement_date'), (0.0138, 'Daily_sum_sunshine'), (0.0087, 'Precipitation_level'), (0.0073, 'Max_Wind_Speed'), (0.0015, 'Daily_snow_depth')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GRADIENT BOOST REGRESSOR RESULTS:\n",
    "\n",
    "Cross validation for Gradient Boost Regressor:\n",
    "\n",
    "Scores:\n",
    " [2.46144202 2.6106133  2.71846869 2.42573004 2.41835414 2.19251581\n",
    " 2.02940613 2.05589875 2.02517665 2.16819998]\n",
    "\n",
    "Mean:\n",
    " 2.3105805499360836\n",
    "\n",
    "Standard deviation:\n",
    " 0.23740574825514552\n",
    "\n",
    "------------------------------------------------\n",
    "R2 of Random Gradient Boost Regressor test:\n",
    " 0.9443361562711963\n",
    "\n",
    "MSE of Gradient Boosting Reg with Early Stopping test:\n",
    " 4.614403706082692\n",
    "\n",
    "RMSE of Gradient Boosting Reg with Early Stopping test:\n",
    " 2.14811631577126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGB RESULTS:\n",
    "\n",
    "Cross validation for Extreme Gradient Boosting:\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[14:28:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "\n",
    "Scores:\n",
    " [2.45119363 2.59078281 2.71517073 2.33522507 2.41367337 2.16860214\n",
    " 2.0447308  2.05735058 2.02073665 2.16213441]\n",
    "\n",
    "Mean:\n",
    " 2.295960016382389\n",
    "\n",
    "Standard deviation:\n",
    " 0.23066893137791764\n",
    "\n",
    "---------------------------------------------\n",
    "R2 of Extreme Gradient Boosting test:\n",
    " 0.9428718104874952\n",
    "\n",
    "MSE of Extreme Gradient Boosting Reg test:\n",
    " 4.735794579559151\n",
    "\n",
    "RMSE of Extreme Gradient Boosting Reg test:\n",
    " 2.17618808460095 \n",
    "\n",
    "[14:28:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
    "[0]\tvalidation_0-rmse:15.305\n",
    "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
    "[1]\tvalidation_0-rmse:13.9334\n",
    "[2]\tvalidation_0-rmse:12.7045\n",
    "[3]\tvalidation_0-rmse:11.6005\n",
    "[4]\tvalidation_0-rmse:10.6201\n",
    "[5]\tvalidation_0-rmse:9.72642\n",
    "[6]\tvalidation_0-rmse:8.93128\n",
    "[7]\tvalidation_0-rmse:8.22914\n",
    "[8]\tvalidation_0-rmse:7.57611\n",
    "[9]\tvalidation_0-rmse:7.00887\n",
    "[10]\tvalidation_0-rmse:6.50235\n",
    "[11]\tvalidation_0-rmse:6.03035\n",
    "[12]\tvalidation_0-rmse:5.63829\n",
    "[13]\tvalidation_0-rmse:5.24719\n",
    "[14]\tvalidation_0-rmse:4.91378\n",
    "[15]\tvalidation_0-rmse:4.63882\n",
    "[16]\tvalidation_0-rmse:4.38901\n",
    "[17]\tvalidation_0-rmse:4.17356\n",
    "[18]\tvalidation_0-rmse:3.96963\n",
    "[19]\tvalidation_0-rmse:3.78511\n",
    "[20]\tvalidation_0-rmse:3.61669\n",
    "[21]\tvalidation_0-rmse:3.4738\n",
    "[22]\tvalidation_0-rmse:3.34785\n",
    "[23]\tvalidation_0-rmse:3.251\n",
    "[24]\tvalidation_0-rmse:3.15557\n",
    "[25]\tvalidation_0-rmse:3.05671\n",
    "[26]\tvalidation_0-rmse:2.97558\n",
    "[27]\tvalidation_0-rmse:2.91375\n",
    "[28]\tvalidation_0-rmse:2.85326\n",
    "[29]\tvalidation_0-rmse:2.80527\n",
    "[30]\tvalidation_0-rmse:2.75502\n",
    "[31]\tvalidation_0-rmse:2.70889\n",
    "[32]\tvalidation_0-rmse:2.66224\n",
    "[33]\tvalidation_0-rmse:2.62941\n",
    "[34]\tvalidation_0-rmse:2.59947\n",
    "[35]\tvalidation_0-rmse:2.57668\n",
    "[36]\tvalidation_0-rmse:2.55088\n",
    "[37]\tvalidation_0-rmse:2.52406\n",
    "[38]\tvalidation_0-rmse:2.50567\n",
    "[39]\tvalidation_0-rmse:2.48324\n",
    "[40]\tvalidation_0-rmse:2.47027\n",
    "[41]\tvalidation_0-rmse:2.45218\n",
    "[42]\tvalidation_0-rmse:2.44227\n",
    "[43]\tvalidation_0-rmse:2.42505\n",
    "[44]\tvalidation_0-rmse:2.4176\n",
    "[45]\tvalidation_0-rmse:2.40451\n",
    "[46]\tvalidation_0-rmse:2.39883\n",
    "[47]\tvalidation_0-rmse:2.38189\n",
    "[48]\tvalidation_0-rmse:2.37384\n",
    "[49]\tvalidation_0-rmse:2.36433\n",
    "[50]\tvalidation_0-rmse:2.35832\n",
    "[51]\tvalidation_0-rmse:2.35284\n",
    "[52]\tvalidation_0-rmse:2.34517\n",
    "[53]\tvalidation_0-rmse:2.34068\n",
    "[54]\tvalidation_0-rmse:2.3379\n",
    "[55]\tvalidation_0-rmse:2.33861\n",
    "[56]\tvalidation_0-rmse:2.33039\n",
    "[57]\tvalidation_0-rmse:2.31978\n",
    "[58]\tvalidation_0-rmse:2.31569\n",
    "[59]\tvalidation_0-rmse:2.31659\n",
    "[60]\tvalidation_0-rmse:2.31344\n",
    "[61]\tvalidation_0-rmse:2.31064\n",
    "[62]\tvalidation_0-rmse:2.30336\n",
    "[63]\tvalidation_0-rmse:2.30116\n",
    "[64]\tvalidation_0-rmse:2.29246\n",
    "[65]\tvalidation_0-rmse:2.28914\n",
    "[66]\tvalidation_0-rmse:2.28817\n",
    "[67]\tvalidation_0-rmse:2.28434\n",
    "[68]\tvalidation_0-rmse:2.28319\n",
    "[69]\tvalidation_0-rmse:2.28265\n",
    "[70]\tvalidation_0-rmse:2.27944\n",
    "[71]\tvalidation_0-rmse:2.27498\n",
    "[72]\tvalidation_0-rmse:2.27361\n",
    "[73]\tvalidation_0-rmse:2.27099\n",
    "[74]\tvalidation_0-rmse:2.26737\n",
    "[75]\tvalidation_0-rmse:2.26652\n",
    "[76]\tvalidation_0-rmse:2.26488\n",
    "[77]\tvalidation_0-rmse:2.2508\n",
    "[78]\tvalidation_0-rmse:2.24538\n",
    "[79]\tvalidation_0-rmse:2.24497\n",
    "[80]\tvalidation_0-rmse:2.22572\n",
    "[81]\tvalidation_0-rmse:2.2232\n",
    "[82]\tvalidation_0-rmse:2.21623\n",
    "[83]\tvalidation_0-rmse:2.21642\n",
    "[84]\tvalidation_0-rmse:2.2155\n",
    "[85]\tvalidation_0-rmse:2.20993\n",
    "[86]\tvalidation_0-rmse:2.20805\n",
    "[87]\tvalidation_0-rmse:2.20826\n",
    "[88]\tvalidation_0-rmse:2.19419\n",
    "[89]\tvalidation_0-rmse:2.19362\n",
    "[90]\tvalidation_0-rmse:2.19173\n",
    "[91]\tvalidation_0-rmse:2.19095\n",
    "[92]\tvalidation_0-rmse:2.18022\n",
    "[93]\tvalidation_0-rmse:2.17817\n",
    "[94]\tvalidation_0-rmse:2.1784\n",
    "[95]\tvalidation_0-rmse:2.17787\n",
    "[96]\tvalidation_0-rmse:2.17892\n",
    "[97]\tvalidation_0-rmse:2.17945\n",
    "[98]\tvalidation_0-rmse:2.17681\n",
    "[99]\tvalidation_0-rmse:2.17619"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
